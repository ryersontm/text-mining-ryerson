{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grand-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import sys\n",
    "import batch_char as batch\n",
    "import pickle as pkl\n",
    "import io\n",
    "import os\n",
    "\n",
    "from t2v import tweet2vec, init_params, load_params\n",
    "from settings_char import N_BATCH, MAX_LENGTH, MAX_CLASSES\n",
    "\n",
    "\n",
    "#setting up conditions for Theano:\n",
    "theano.config.gcc.cxxflags = \"-Wno-c++11-narrowing\"\n",
    "os.environ['THEANO_FLAGS'] = \"device=cpu,floatX=float32\"\n",
    "\n",
    "\n",
    "def invert(d):\n",
    "    out = {}\n",
    "    for k,v in d.items():\n",
    "        out[v] = k\n",
    "    return out\n",
    "\n",
    "def classify(tweet, t_mask, params, n_classes, n_chars):\n",
    "    # tweet embedding\n",
    "    emb_layer = tweet2vec(tweet, t_mask, params, n_chars)\n",
    "    # Dense layer for classes\n",
    "    l_dense = lasagne.layers.DenseLayer(emb_layer, n_classes, W=params['W_cl'], b=params['b_cl'], nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return lasagne.layers.get_output(l_dense), lasagne.layers.get_output(emb_layer)\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_path = \"/users/kumaraprasannajayaraju/Downloads/NLP_Final_Project/Method 1/data/life_t2v_ds_en_op.txt\"\n",
    "    model_path = \"/users/kumaraprasannajayaraju/Downloads/NLP_Final_Project/Method 1/src\"\n",
    "    save_path = \"/users/kumaraprasannajayaraju/Downloads/NLP_Final_Project/Method 1/data\"\n",
    "    if len(args)>3:\n",
    "        m_num = int(args[3])\n",
    "\n",
    "    print(\"Preparing Data...\")\n",
    "    # Test data\n",
    "    Xt = []\n",
    "    with io.open(data_path,'r',encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            Xc = line.rstrip('\\n')\n",
    "            Xt.append(Xc[:MAX_LENGTH])\n",
    "\n",
    "    # Model\n",
    "    print(\"Loading model params...\")\n",
    "    if len(args)>3:\n",
    "        params = load_params('%s/model-nlp-t2v_%d.npz' % (model_path,m_num))\n",
    "    else:\n",
    "        params = load_params('%s/best_model-nlp-t2v.npz' % model_path)\n",
    "\n",
    "    print(\"Loading dictionaries...\")\n",
    "    with open('%s/dict-2-nlp-t2v.pkl' % model_path, 'rb') as f:\n",
    "        chardict = pkl.load(f)\n",
    "    with open('%s/label_dict-2-nlp-t2v.pkl' % model_path, 'rb') as f:\n",
    "        labeldict = pkl.load(f)\n",
    "    n_char = len(chardict.keys()) + 1\n",
    "    n_classes = min(len(labeldict.keys()) + 1, MAX_CLASSES)\n",
    "    inverse_labeldict = invert(labeldict)\n",
    "\n",
    "    print(\"Building network...\")\n",
    "    # Tweet variables\n",
    "    tweet = T.itensor3()\n",
    "    t_mask = T.fmatrix()\n",
    "\n",
    "    # network for prediction\n",
    "    predictions, embeddings = classify(tweet, t_mask, params, n_classes, n_char)\n",
    "\n",
    "    # Theano function\n",
    "    print(\"Compiling theano functions...\")\n",
    "    predict = theano.function([tweet,t_mask],predictions)\n",
    "    encode = theano.function([tweet,t_mask],embeddings)\n",
    "\n",
    "    # Test\n",
    "    print(\"Encoding...\")\n",
    "    out_pred = []\n",
    "    out_emb = []\n",
    "    numbatches = int(len(Xt)/N_BATCH + 1)\n",
    "    for i in range(numbatches):\n",
    "        xr = Xt[N_BATCH*i:N_BATCH*(i+1)]\n",
    "        x, x_m = batch.prepare_data(xr, chardict, n_chars=n_char)\n",
    "        p = predict(x,x_m)\n",
    "        e = encode(x,x_m)\n",
    "        ranks = np.argsort(p)[:,::-1]\n",
    "\n",
    "        for idx, item in enumerate(xr):\n",
    "            out_pred.append(' '.join([inverse_labeldict[r] if r in inverse_labeldict else 'UNK' for r in ranks[idx,:5]]))\n",
    "            out_emb.append(e[idx,:])\n",
    "\n",
    "    # Save\n",
    "    print(\"Saving...\")\n",
    "    with io.open('%s/predicted_tags-nlp-t2v.txt'%save_path,'w') as f:\n",
    "        for item in out_pred:\n",
    "            f.write(item + '\\n')\n",
    "    with open('%s/embeddings-nlp-t2v.npy'%save_path,'wb') as f:\n",
    "        np.save(f,np.asarray(out_emb))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-measure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
