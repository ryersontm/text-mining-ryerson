{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch.nn.functional as F \n",
    "import pickle\n",
    "import scipy.io\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import gensim\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('stops.txt', 'r') as f:\n",
    "    stops = f.read().split('\\n')\n",
    "stops[0:5]\n",
    "\n",
    "\n",
    "data_clean = [re.findall(r'''[\\w']+|[.,!?;-~{}`Â´_<=>:/@*()&'$%#\"]''',data[doc]) for doc in range(len(data))]\n",
    "\n",
    "def contains_punctuation(w):\n",
    "    return any(char in string.punctuation for char in w)\n",
    "\n",
    "def contains_numeric(w):\n",
    "    return any(char.isdigit() for char in w)\n",
    "\n",
    "data_clean = [[w.lower() for w in data_clean[doc] if not contains_punctuation(w)] for doc in range(len(data_clean))]\n",
    "data_clean = [[w for w in data_clean[doc] if not contains_numeric(w)] for doc in range(len(data_clean))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count=2\n",
    "dim_rho = 300 #dimensionality of the word embeddings\n",
    "iters = 50\n",
    "workers = 25\n",
    "negative_samples = 10\n",
    "window_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "model = gensim.models.Word2Vec(data_clean, min_count=min_count, sg=1, size=dim_rho, \n",
    "    iter=iters, workers=workers, negative=negative_samples, window=window_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings.txt', 'w') as f:\n",
    "    for v in list(model.wv.vocab):\n",
    "        vec = list(model.wv.__getitem__(v))\n",
    "        f.write(v + ' ')\n",
    "        vec_str = ['%.9f' % val for val in vec]\n",
    "        vec_str = \" \".join(vec_str)\n",
    "        f.write(vec_str + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
